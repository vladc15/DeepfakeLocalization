{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def list_all_files_in_directory(directory_path):\n",
    "    directory_path = os.path.abspath(directory_path)\n",
    "    all_file_paths = []\n",
    "    for _, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            all_file_paths.append(file)\n",
    "\n",
    "    return all_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filename_without_extension(file_path):\n",
    "    base_name = os.path.basename(file_path)\n",
    "    return os.path.splitext(base_name)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial files:\n",
      "train --> 9000\n",
      "test --> 900\n",
      "valid --> 900\n",
      "\n",
      "Randomized files:\n",
      "train --> 3000\n",
      "test --> 900\n",
      "valid --> 300\n"
     ]
    }
   ],
   "source": [
    "dataset_root_path = './datasets/dolos_data/celebahq/fake/'\n",
    "\n",
    "all_files = {\n",
    "    \"train\": [\n",
    "        extract_filename_without_extension(f)\n",
    "        for f in list_all_files_in_directory(os.path.join(dataset_root_path, \"lama/images/train\"))\n",
    "    ],\n",
    "    \"test\": [\n",
    "        extract_filename_without_extension(f)\n",
    "        for f in list_all_files_in_directory(os.path.join(dataset_root_path, \"lama/images/test\"))\n",
    "    ],\n",
    "    \"valid\": [\n",
    "        extract_filename_without_extension(f)\n",
    "        for f in list_all_files_in_directory(os.path.join(dataset_root_path, \"lama/images/valid\"))\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"Initial files:\")\n",
    "print(\"train -->\", len(all_files[\"train\"]))\n",
    "print(\"test -->\", len(all_files[\"test\"]))\n",
    "print(\"valid -->\", len(all_files[\"valid\"]))\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "random.shuffle(all_files[\"train\"])\n",
    "random.shuffle(all_files[\"test\"])\n",
    "random.shuffle(all_files[\"valid\"])\n",
    "\n",
    "\n",
    "all_files[\"train\"] = all_files[\"train\"][:3000]\n",
    "all_files[\"valid\"] = all_files[\"valid\"][:300]\n",
    "\n",
    "print()\n",
    "print(\"Randomized files:\")\n",
    "print(\"train -->\", len(all_files[\"train\"]))\n",
    "print(\"test -->\", len(all_files[\"test\"]))\n",
    "print(\"valid -->\", len(all_files[\"valid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\"ldm\", \"repaint-p2-9k\", \"lama\", \"pluralistic\"]\n",
    "test = [\"ldm\", \"repaint-p2-9k\", \"lama\", \"pluralistic\"]\n",
    "result_dir = \"train_all_4_datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(result_dir)\n",
    "\n",
    "images_dir = os.path.join(result_dir, \"images\")\n",
    "os.makedirs(images_dir)\n",
    "\n",
    "masks_dir = os.path.join(result_dir, \"masks\")\n",
    "os.makedirs(masks_dir)\n",
    "\n",
    "for dir in [\"test\", \"train\", \"valid\"]:\n",
    "    os.makedirs(os.path.join(images_dir, dir))\n",
    "    os.makedirs(os.path.join(masks_dir, dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for dataset_selected in train:\n",
    "    for type in [\"images\", \"masks\"]:\n",
    "        for set in [\"train\", \"valid\"]:\n",
    "            for file in all_files[set]:\n",
    "                path = f\"{dataset_root_path}{dataset_selected}/{type}/{set}/{file}.png\"\n",
    "                new_path = f\"{result_dir}/{type}/{set}\"\n",
    "                shutil.copy(path, new_path)\n",
    "                os.rename(\n",
    "                    f\"{new_path}/{file}.png\",\n",
    "                    f\"{result_dir}/{type}/{set}/{file}_{dataset_selected}.png\",\n",
    "                )\n",
    "for test_dataset_selected in test:\n",
    "    for type in [\"images\", \"masks\"]:\n",
    "        for file in all_files[\"test\"]:\n",
    "            path = f\"{dataset_root_path}{test_dataset_selected}/{type}/test/{file}.png\"\n",
    "            new_path = f\"{result_dir}/{type}/test\"\n",
    "            shutil.copy(path, new_path)\n",
    "            os.rename(\n",
    "                f\"{new_path}/{file}.png\",\n",
    "                f\"{result_dir}/{type}/test/{file}_{test_dataset_selected}.png\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "12000\n",
      "3600\n",
      "3600\n",
      "1200\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "print(len(list_all_files_in_directory(result_dir + \"/images/train\")))\n",
    "print(len(list_all_files_in_directory(result_dir + \"/masks/train\")))\n",
    "print(len(list_all_files_in_directory(result_dir + \"/images/test\")))\n",
    "print(len(list_all_files_in_directory(result_dir + \"/masks/test\")))\n",
    "print(len(list_all_files_in_directory(result_dir + \"/images/valid\")))\n",
    "print(len(list_all_files_in_directory(result_dir + \"/masks/valid\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
