{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90198a98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90198a98",
        "outputId": "e5362795-8491-48a7-a658-5e70d31ec9f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mXmVMLyLr5ar",
      "metadata": {
        "id": "mXmVMLyLr5ar"
      },
      "outputs": [],
      "source": [
        "# update working directory\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ub5HUP6or_7w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub5HUP6or_7w",
        "outputId": "145c4a30-b5d9-42e6-8273-f51e1bb93de8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.7.1\n",
            "Collecting git+https://github.com/facebookresearch/sam2.git\n",
            "  Cloning https://github.com/facebookresearch/sam2.git to /tmp/pip-req-build-48oc2kgr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/sam2.git /tmp/pip-req-build-48oc2kgr\n",
            "  Resolved https://github.com/facebookresearch/sam2.git to commit 2b90b9f5ceec907a1c18123530e92e794ad901a4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (4.67.1)\n",
            "Collecting hydra-core>=1.3.2 (from SAM-2==1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting iopath>=0.1.10 (from SAM-2==1.0)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (11.2.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (24.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (4.13.2)\n",
            "Collecting portalocker (from iopath>=0.1.10->SAM-2==1.0)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->SAM-2==1.0) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->SAM-2==1.0) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: SAM-2, iopath\n",
            "  Building wheel for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SAM-2: filename=sam_2-1.0-cp311-cp311-linux_x86_64.whl size=472600 sha256=6fae5efca693231b948e44663d2a947d4499c9e491b18f46c4b77cb29d384f06\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mfdnfxi5/wheels/d8/63/41/d37b316a85599f58a42be0210805ecf8594b9c06082028716e\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=94abf2babad2e71dd3bcee27e88ad6e3f966f94760b1ea58aec42f9a78fa5974\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built SAM-2 iopath\n",
            "Installing collected packages: portalocker, iopath, hydra-core, SAM-2\n",
            "Successfully installed SAM-2-1.0 hydra-core-1.3.2 iopath-0.1.10 portalocker-3.1.1\n",
            "--2025-05-19 12:32:22--  https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_small.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.171.22.68, 3.171.22.33, 3.171.22.13, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.171.22.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 184416285 (176M) [application/vnd.snesdev-page-table]\n",
            "Saving to: ‘../checkpoints/sam2.1_hiera_small.pt’\n",
            "\n",
            "sam2.1_hiera_small. 100%[===================>] 175.87M   191MB/s    in 0.9s    \n",
            "\n",
            "2025-05-19 12:32:23 (191 MB/s) - ‘../checkpoints/sam2.1_hiera_small.pt’ saved [184416285/184416285]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/sam2.git' # colab\n",
        "!mkdir -p ../checkpoints/\n",
        "!wget -P ../checkpoints/ https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_small.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QpmTb67Ur4kG",
      "metadata": {
        "id": "QpmTb67Ur4kG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "\n",
        "from parameters import Parameters\n",
        "from deepfake_datasets import LOCALIZATION_DATASET_PATHS, DETECTION_DATASET_PATHS\n",
        "from deepfake_datasets.datasets import get_dataloader\n",
        "from models.declip import get_model\n",
        "from models.declip_detection import get_detection_model\n",
        "from models.sam_localization import get_sam_model\n",
        "from models.two_step_model import TwoStepModel\n",
        "from train.validate import validate_detection, validate_fully_supervised_localization, validate_ensemble_fully_supervised_localization\n",
        "from utils.utils import compute_mean_iou, compute_mean_f1, compute_mean_ap, compute_mean_acc_detection, compute_mean_ap_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb5e0f6",
      "metadata": {
        "id": "fdb5e0f6"
      },
      "outputs": [],
      "source": [
        "# set seed for reproducibility\n",
        "SEED = 0\n",
        "def set_seed():\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "# save image predictions to files\n",
        "def save_image_localization_scores_to_file(ious, f1_best, f1_fixed, aps, img_paths, params, dataset_name):\n",
        "    with open(params.save_dir_results + f\"/scores_{dataset_name}.txt\", 'a') as f:\n",
        "        f.write(f'image path \\t iou \\t f1_best \\t f1_fixed \\t ap\\n')\n",
        "        for iou, f1_b, f1_f, ap, img_path in zip(ious, f1_best, f1_fixed, aps, img_paths):\n",
        "            f.write(f'{img_path} \\t {iou} \\t {f1_b} \\t {f1_f} \\t {ap}\\n')\n",
        "\n",
        "# constants for image processing\n",
        "MEAN = {\n",
        "    \"imagenet\":[0.485, 0.456, 0.406],\n",
        "    \"clip\":[0.48145466, 0.4578275, 0.40821073]\n",
        "}\n",
        "STD = {\n",
        "    \"imagenet\":[0.229, 0.224, 0.225],\n",
        "    \"clip\":[0.26862954, 0.26130258, 0.27577711]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_dataset_name = 'train_all_4_datasets'\n",
        "\n",
        "zip_path = f'/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/datasets_zip/combined_training_for_ood/{new_dataset_name}.zip'\n",
        "new_content_root_path = f'/content/datasets/dolos_data/celebahq/fake/'\n",
        "\n",
        "os.makedirs(new_content_root_path, exist_ok=True)\n",
        "\n",
        "# move the dataset from drive to /content (SSD) for better performance in I/O\n",
        "import zipfile\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(new_content_root_path)"
      ],
      "metadata": {
        "id": "phL80VrEJvRt"
      },
      "id": "phL80VrEJvRt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b46c6d",
      "metadata": {
        "id": "d6b46c6d"
      },
      "outputs": [],
      "source": [
        "# set parameters\n",
        "params = Parameters()\n",
        "\n",
        "# set the experiment name and output directory\n",
        "# alert if the experiment name is not set or the output directory already exists\n",
        "params.experiment_name = 'test_2_step_model'\n",
        "assert params.experiment_name != '', 'Please set the experiment name'\n",
        "experiment_path = f'/content/experiments/{params.experiment_name}'\n",
        "if os.path.exists(experiment_path):\n",
        "    shutil.rmtree(experiment_path)\n",
        "params.create_output_dirs()\n",
        "\n",
        "# set data labels to test\n",
        "params.data_label = 'test'\n",
        "\n",
        "# set the model checkpoint path\n",
        "# params.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/combined_training/test_repaint/best_localization_model_vit+rn50_conv12_iou_65.4029_test_repaint.pth'\n",
        "# assert params.checkpoint_path != '', 'Please set the checkpoint path'\n",
        "\n",
        "# set model parameters for testing\n",
        "# state_dict = torch.load(params.checkpoint_path, map_location='cpu')\n",
        "# params.decoder_type = state_dict['decoder_type']\n",
        "# params.feature_layer = state_dict['feature_layer']\n",
        "\n",
        "# params.arch = 'CLIP:ViT-L/14,RN50'\n",
        "# params.arch = 'CLIP:RN50'\n",
        "\n",
        "params.task_type = 'fully_supervised_localization'\n",
        "\n",
        "# params.test_real_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/datasets/dolos_data/celebahq/'\n",
        "save_dir_res = params.save_dir_results\n",
        "\n",
        "# set the batch size and num threads\n",
        "params.batch_size = 64\n",
        "params.num_threads = 8\n",
        "\n",
        "# for sam models\n",
        "params.sam_checkpoint_path = '../checkpoints/sam2.1_hiera_small.pt'\n",
        "params.sam_config_path = 'configs/sam2.1/sam2.1_hiera_s.yaml'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params_classifier = copy.deepcopy(params)\n",
        "params_classifier.arch = 'CLIP:ViT-L/14'\n",
        "params_classifier.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/classification/best_classification_model_ap_0.8310_all_4.pth'\n",
        "state_dict_classifier = torch.load(params_classifier.checkpoint_path, map_location='cpu')\n",
        "params_classifier.decoder_type = state_dict_classifier['decoder_type']\n",
        "params_classifier.feature_layer = state_dict_classifier['feature_layer']\n",
        "params_classifier.task_type = 'classification'\n",
        "model_classifier = get_detection_model(params_classifier)\n",
        "params_classifier.task_type = 'fully_supervised_localization'\n",
        "model_classifier.load_state_dict(state_dict_classifier['model'], strict=False)\n",
        "model_classifier = model_classifier.cuda()\n",
        "model_classifier.eval()\n",
        "\n",
        "\n",
        "params_ldm = copy.deepcopy(params)\n",
        "params_ldm.arch = 'CLIP:ViT-L/14,RN50'\n",
        "params_ldm.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/initial_training/vit+rn50/best_localization_model_vit+rn50_conv12_iou_51.3407_ldm.pth'\n",
        "state_dict_ldm = torch.load(params_ldm.checkpoint_path, map_location='cpu')\n",
        "params_ldm.decoder_type = state_dict_ldm['decoder_type']\n",
        "params_ldm.feature_layer = state_dict_ldm['feature_layer']\n",
        "model_ldm = get_model(params_ldm)\n",
        "model_ldm.load_state_dict(state_dict_ldm['model'], strict=False)\n",
        "model_ldm = model_ldm.cuda()\n",
        "model_ldm.eval()\n",
        "\n",
        "params_repaint = copy.deepcopy(params)\n",
        "params_repaint.arch = 'CLIP:ViT-L/14,RN50'\n",
        "params_repaint.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/initial_training/vit+rn50/best_localization_model_vit+rn50_conv12_iou_73.5066_repaint.pth'\n",
        "state_dict_repaint = torch.load(params_repaint.checkpoint_path, map_location='cpu')\n",
        "params_repaint.decoder_type = state_dict_repaint['decoder_type']\n",
        "params_repaint.feature_layer = state_dict_repaint['feature_layer']\n",
        "model_repaint = get_model(params_repaint)\n",
        "model_repaint.load_state_dict(state_dict_repaint['model'], strict=False)\n",
        "model_repaint = model_repaint.cuda()\n",
        "model_repaint.eval()\n",
        "\n",
        "params_lama = copy.deepcopy(params)\n",
        "params_lama.arch = 'SAM2'\n",
        "# params_lama.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/initial_training/vit+rn50/best_localization_model_vit+rn50_conv12_iou_85.2398_lama.pth'\n",
        "params_lama.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/SAM-DeepfakeLocalization-local/trained_models/train_new/lama/high_res_feats_0_32_64/best_localization_model_iou_92.7912.pth'\n",
        "state_dict_lama = torch.load(params_lama.checkpoint_path, map_location='cpu')\n",
        "params_lama.decoder_type = state_dict_lama['decoder_type']\n",
        "params_lama.feature_layer = state_dict_lama['feature_layer']\n",
        "# model_lama = get_model(params_lama)\n",
        "model_lama_sam = get_sam_model(params_lama)\n",
        "model_lama_sam.load_state_dict(state_dict_lama['model'], strict=False)\n",
        "model_lama_sam = model_lama_sam.cuda()\n",
        "model_lama_sam.eval()\n",
        "\n",
        "params_pluralistic = copy.deepcopy(params)\n",
        "params_pluralistic.arch = 'SAM2'\n",
        "# params_pluralistic.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/initial_training/vit+rn50/best_localization_model_vit+rn50_conv12_iou_83.1698_pluralistic.pth'\n",
        "params_pluralistic.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/SAM-DeepfakeLocalization-local/trained_models/train_new/pluralistic/high_res_feats_0_32_64/best_localization_model_iou_91.2513.pth'\n",
        "state_dict_pluralistic = torch.load(params_pluralistic.checkpoint_path, map_location='cpu')\n",
        "params_pluralistic.decoder_type = state_dict_pluralistic['decoder_type']\n",
        "params_pluralistic.feature_layer = state_dict_pluralistic['feature_layer']\n",
        "model_pluralistic_sam = get_sam_model(params_pluralistic)\n",
        "model_pluralistic_sam.load_state_dict(state_dict_pluralistic['model'], strict=False)\n",
        "model_pluralistic_sam = model_pluralistic_sam.cuda()\n",
        "model_pluralistic_sam.eval()\n",
        "\n",
        "# sam got the best results on GAN-based manipulations\n",
        "localization_models_sam = {\n",
        "    'ldm': model_ldm,\n",
        "    'repaint': model_repaint,\n",
        "    'lama': model_lama_sam,\n",
        "    'pluralistic': model_pluralistic_sam\n",
        "}\n",
        "\n",
        "# now let's illustrate the clip models as well\n",
        "params_lama = copy.deepcopy(params)\n",
        "params_lama.arch = 'CLIP:ViT-L/14,RN50'\n",
        "params_lama.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/initial_training/vit+rn50/best_localization_model_vit+rn50_conv12_iou_85.2398_lama.pth'\n",
        "state_dict_lama = torch.load(params_lama.checkpoint_path, map_location='cpu')\n",
        "params_lama.decoder_type = state_dict_lama['decoder_type']\n",
        "params_lama.feature_layer = state_dict_lama['feature_layer']\n",
        "model_lama_clip = get_model(params_lama)\n",
        "model_lama_clip.load_state_dict(state_dict_lama['model'], strict=False)\n",
        "model_lama_clip = model_lama_clip.cuda()\n",
        "model_lama_clip.eval()\n",
        "\n",
        "params_pluralistic = copy.deepcopy(params)\n",
        "params_pluralistic.arch = 'CLIP:ViT-L/14,RN50'\n",
        "params_pluralistic.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/initial_training/vit+rn50/best_localization_model_vit+rn50_conv12_iou_83.1698_pluralistic.pth'\n",
        "state_dict_pluralistic = torch.load(params_pluralistic.checkpoint_path, map_location='cpu')\n",
        "params_pluralistic.decoder_type = state_dict_pluralistic['decoder_type']\n",
        "params_pluralistic.feature_layer = state_dict_pluralistic['feature_layer']\n",
        "model_pluralistic_clip = get_model(params_pluralistic)\n",
        "model_pluralistic_clip.load_state_dict(state_dict_pluralistic['model'], strict=False)\n",
        "model_pluralistic_clip = model_pluralistic_clip.cuda()\n",
        "model_pluralistic_clip.eval()\n",
        "\n",
        "\n",
        "localization_models_clip = {\n",
        "    'ldm': model_ldm,\n",
        "    'repaint': model_repaint,\n",
        "    'lama': model_lama_clip,\n",
        "    'pluralistic': model_pluralistic_clip\n",
        "}"
      ],
      "metadata": {
        "id": "3QTGYV3xyG0w"
      },
      "id": "3QTGYV3xyG0w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_detector = copy.deepcopy(params)\n",
        "params_detector.arch = 'CLIP:ViT-L/14'\n",
        "params_detector.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/detection/best_detection_model_ap_0.8992_all_4.pth' # detector trained on all 4\n",
        "state_dict_detector = torch.load(params_detector.checkpoint_path, map_location='cpu')\n",
        "params_detector.decoder_type = state_dict_detector['decoder_type']\n",
        "params_detector.feature_layer = state_dict_detector['feature_layer']\n",
        "params_detector.task_type = 'detection'\n",
        "model_detector = get_detection_model(params_detector)\n",
        "params_detector.task_type = 'fully_supervised_localization'\n",
        "model_detector.load_state_dict(state_dict_detector['model'], strict=False)\n",
        "model_detector = model_detector.cuda()\n",
        "model_detector.eval()\n",
        "\n",
        "\n",
        "params_combined_training_all_4 = copy.deepcopy(params)\n",
        "params_combined_training_all_4.arch = 'CLIP:ViT-L/14,RN50'\n",
        "params_combined_training_all_4.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/combined_training/train_all_4/best_localization_model_vit+rn50_conv12_iou_63.5034.pth'\n",
        "state_dict_combined_training_all_4 = torch.load(params_combined_training_all_4.checkpoint_path, map_location='cpu')\n",
        "params_combined_training_all_4.decoder_type = state_dict_combined_training_all_4['decoder_type']\n",
        "params_combined_training_all_4.feature_layer = state_dict_combined_training_all_4['feature_layer']\n",
        "model_combined_training_all_4 = get_model(params_combined_training_all_4)\n",
        "model_combined_training_all_4.load_state_dict(state_dict_combined_training_all_4['model'], strict=False)\n",
        "model_combined_training_all_4 = model_combined_training_all_4.cuda()\n",
        "model_combined_training_all_4.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6UJXqcCdJht",
        "outputId": "ca89af48-4d79-4729-e6cb-a3b5d3a79c3d"
      },
      "id": "m6UJXqcCdJht",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLIPModelLocalisation(\n",
              "  (fc): Sequential(\n",
              "    (0): Conv2d(2048, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU()\n",
              "    (6): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): ReLU()\n",
              "    (9): Upsample(scale_factor=2.0, mode='bilinear')\n",
              "    (10): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (11): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU()\n",
              "    (13): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (15): ReLU()\n",
              "    (16): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (17): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (18): ReLU()\n",
              "    (19): Upsample(scale_factor=2.0, mode='bilinear')\n",
              "    (20): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU()\n",
              "    (23): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (24): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (25): ReLU()\n",
              "    (26): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (27): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (28): ReLU()\n",
              "    (29): Upsample(scale_factor=2.0, mode='bilinear')\n",
              "    (30): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (31): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU()\n",
              "    (33): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (34): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (35): ReLU()\n",
              "    (36): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (37): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (38): ReLU()\n",
              "    (39): Upsample(scale_factor=2.0, mode='bilinear')\n",
              "    (40): Upsample(size=(256, 256), mode='bilinear')\n",
              "    (41): Conv2d(64, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "two_step_model_classifier_sam = TwoStepModel(model_classifier, localization_models_sam, first_step_type='classifier')\n",
        "\n",
        "two_step_model_classifier_clip = TwoStepModel(model_classifier, localization_models_clip, first_step_type='classifier')\n",
        "\n",
        "two_step_model_detector = TwoStepModel(model_detector, model_combined_training_all_4, first_step_type='detector')\n",
        "\n",
        "two_step_models = {\n",
        "    'detector': two_step_model_detector,\n",
        "    'classifier_sam': two_step_model_classifier_sam,\n",
        "    'classifier_clip': two_step_model_classifier_clip\n",
        "}"
      ],
      "metadata": {
        "id": "cAHv9ooedRfR"
      },
      "id": "cAHv9ooedRfR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the datasets and the results file\n",
        "if params.task_type == 'fully_supervised_localization':\n",
        "    dataset_paths = LOCALIZATION_DATASET_PATHS\n",
        "    with open(os.path.join(params.save_dir_results, 'scores.txt'), 'a') as f:\n",
        "        f.write('dataset \\t iou \\t f1_best \\t f1_fixed \\t ap \\n')\n",
        "elif params.task_type == 'detection':\n",
        "    dataset_paths = DETECTION_DATASET_PATHS\n",
        "    with open(os.path.join(params.save_dir_results, 'scores.txt'), 'a') as f:\n",
        "        f.write('dataset \\t ap \\t acc_fixed_thresh \\t acc_best_thresh \\t best_threshold \\n')"
      ],
      "metadata": {
        "id": "SdWGgjuvzh_l"
      },
      "id": "SdWGgjuvzh_l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params.batch_size = 32\n",
        "params.num_threads = 4"
      ],
      "metadata": {
        "id": "oDLW2-ilTC6p"
      },
      "id": "oDLW2-ilTC6p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first test will include real images, so that both two-step models can be used\n",
        "\n",
        "# we will use the specific test sets first (adding real images)\n",
        "\n",
        "for first_step_type in two_step_models.keys():\n",
        "    params.save_dir_results = f'{save_dir_res}_2_step_model_{first_step_type}_on_specific_datasets+real_images'\n",
        "    two_step_model = two_step_models[first_step_type]\n",
        "    print(f'Testing Two Step Model with first step type: {first_step_type} on specific datasets + real images')\n",
        "\n",
        "    for dataset_path in dataset_paths:\n",
        "        if 'autosplice' in dataset_path['key']:\n",
        "            continue\n",
        "        print(f\"Testing on {dataset_path['key']}\")\n",
        "        set_seed()\n",
        "        os.makedirs(os.path.join(params.save_dir_results, dataset_path['key']), exist_ok=True)\n",
        "\n",
        "        params.train_dataset = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['key'])\n",
        "        params.test_fake_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['fake_path'])\n",
        "        params.test_masks_ground_truth_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['masks_path'])\n",
        "        params.test_real_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['real_path'])\n",
        "\n",
        "        params.task_type = 'fully_supervised_localization_with_real_images'\n",
        "        # if 'sam' in first_step_type and (dataset_path['key'] == 'lama' or dataset_path['key'] == 'pluralistic'):\n",
        "        #     prev_arch = params.arch\n",
        "        #     params.arch = 'SAM2'\n",
        "        data_loader = get_dataloader(params)\n",
        "        # if 'sam' in first_step_type and (dataset_path['key'] == 'lama' or dataset_path['key'] == 'pluralistic'):\n",
        "        #     params.arch = prev_arch\n",
        "        params.task_type = 'fully_supervised_localization'\n",
        "\n",
        "        # create the directory for dataset results\n",
        "        os.makedirs(os.path.join(params.save_dir_results, params.train_dataset), exist_ok=True)\n",
        "\n",
        "        if params.task_type == 'fully_supervised_localization':\n",
        "            ious, f1_best, f1_fixed, ap, original_img_paths = validate_ensemble_fully_supervised_localization(\n",
        "                two_step_model, data_loader, dataset_path['key'], params.save_dir_results\n",
        "            )\n",
        "            save_image_localization_scores_to_file(ious, f1_best, f1_fixed, ap, original_img_paths, params, dataset_path['key'])\n",
        "\n",
        "            mean_iou = compute_mean_iou(ious, verbose=True, extra_text=dataset_path['key'])\n",
        "            mean_f1_best, mean_f1_fixed = compute_mean_f1(f1_best, f1_fixed, verbose=True, extra_text=dataset_path['key'])\n",
        "            mean_ap = compute_mean_ap(ap, verbose=True, extra_text=dataset_path['key'])\n",
        "\n",
        "            with open(os.path.join(params.save_dir_results, f\"scores_{dataset_path['key']}.txt\"), 'a') as f:\n",
        "                f.write(f\"{dataset_path['key']} \\t {mean_iou:.4f} \\t {mean_f1_best:.4f} \\t {mean_f1_fixed:.4f} \\t {mean_ap:.4f} \\n\")\n",
        "\n",
        "        print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lACZOV7acMA7",
        "outputId": "403fab00-fb35-42e5-ec1b-aa69a6ef2eb9"
      },
      "id": "lACZOV7acMA7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Two Step Model with first step type: detector on specific datasets + real images\n",
            "Testing on lama\n",
            "Length of dataset:  1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/57 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples found in target, recall is undefined. Setting recall to one for all thresholds.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "100%|██████████| 57/57 [02:20<00:00,  2.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lamaMean IOU: 78.63\n",
            "lamaMean F1 best: 0.8689\n",
            "lamaMean F1 fixed: 0.8436\n",
            "lamaMean AP: 0.4557\n",
            "\n",
            "Testing on ldm\n",
            "Length of dataset:  1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [02:19<00:00,  2.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ldmMean IOU: 63.11\n",
            "ldmMean F1 best: 0.7417\n",
            "ldmMean F1 fixed: 0.6727\n",
            "ldmMean AP: 0.3314\n",
            "\n",
            "Testing on pluralistic\n",
            "Length of dataset:  1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [02:16<00:00,  2.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pluralisticMean IOU: 74.19\n",
            "pluralisticMean F1 best: 0.8306\n",
            "pluralisticMean F1 fixed: 0.8062\n",
            "pluralisticMean AP: 0.4066\n",
            "\n",
            "Testing on repaint-p2-9k\n",
            "Length of dataset:  1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [02:09<00:00,  2.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repaint-p2-9kMean IOU: 62.22\n",
            "repaint-p2-9kMean F1 best: 0.703\n",
            "repaint-p2-9kMean F1 fixed: 0.6898\n",
            "repaint-p2-9kMean AP: 0.2699\n",
            "\n",
            "Testing Two Step Model with first step type: classifier_sam on specific datasets + real images\n",
            "Testing on lama\n",
            "Length of dataset:  1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [02:37<00:00,  2.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lamaMean IOU: 93.52\n",
            "lamaMean F1 best: 0.9601\n",
            "lamaMean F1 fixed: 0.9543\n",
            "lamaMean AP: 0.4904\n",
            "\n",
            "Testing on ldm\n",
            "Length of dataset:  1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [02:18<00:00,  2.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ldmMean IOU: 72.61\n",
            "ldmMean F1 best: 0.8294\n",
            "ldmMean F1 fixed: 0.7663\n",
            "ldmMean AP: 0.3483\n",
            "\n",
            "Testing on pluralistic\n",
            "Length of dataset:  1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [02:29<00:00,  2.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pluralisticMean IOU: 85.46\n",
            "pluralisticMean F1 best: 0.8967\n",
            "pluralisticMean F1 fixed: 0.8905\n",
            "pluralisticMean AP: 0.4078\n",
            "\n",
            "Testing on repaint-p2-9k\n",
            "Length of dataset:  1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [02:06<00:00,  2.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repaint-p2-9kMean IOU: 64.46\n",
            "repaint-p2-9kMean F1 best: 0.7188\n",
            "repaint-p2-9kMean F1 fixed: 0.7034\n",
            "repaint-p2-9kMean AP: 0.2205\n",
            "\n",
            "Testing Two Step Model with first step type: classifier_clip on specific datasets + real images\n",
            "Testing on lama\n",
            "Length of dataset:  1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [02:16<00:00,  2.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lamaMean IOU: 89.73\n",
            "lamaMean F1 best: 0.9606\n",
            "lamaMean F1 fixed: 0.9533\n",
            "lamaMean AP: 0.4822\n",
            "\n",
            "Testing on ldm\n",
            "Length of dataset:  1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [02:18<00:00,  2.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ldmMean IOU: 72.42\n",
            "ldmMean F1 best: 0.8273\n",
            "ldmMean F1 fixed: 0.7646\n",
            "ldmMean AP: 0.349\n",
            "\n",
            "Testing on pluralistic\n",
            "Length of dataset:  1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [02:13<00:00,  2.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pluralisticMean IOU: 82.37\n",
            "pluralisticMean F1 best: 0.8953\n",
            "pluralisticMean F1 fixed: 0.8862\n",
            "pluralisticMean AP: 0.4005\n",
            "\n",
            "Testing on repaint-p2-9k\n",
            "Length of dataset:  1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 57/57 [02:05<00:00,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repaint-p2-9kMean IOU: 64.5\n",
            "repaint-p2-9kMean F1 best: 0.7186\n",
            "repaint-p2-9kMean F1 fixed: 0.7054\n",
            "repaint-p2-9kMean AP: 0.2243\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can test on all test sets at once\n",
        "\n",
        "for first_step_type in two_step_models.keys():\n",
        "    params.save_dir_results = f'{save_dir_res}_2_step_model_{first_step_type}_on_all_datasets'\n",
        "    two_step_model = two_step_models[first_step_type]\n",
        "    print(f'Testing Two Step Model with first step type: {first_step_type} on all datasets')\n",
        "\n",
        "    dataset_path_all_4 = dict(\n",
        "            fake_path=f'datasets/dolos_data/celebahq/fake/train_all_4_datasets/images/test',\n",
        "            real_path=f'datasets/dolos_data/celebahq/real/test',\n",
        "            masks_path=f'datasets/dolos_data/celebahq/fake/train_all_4_datasets/masks/test',\n",
        "            key='train_all_4_datasets'\n",
        "        )\n",
        "\n",
        "    print(f\"Testing on {dataset_path_all_4['key']}\")\n",
        "    set_seed()\n",
        "    os.makedirs(os.path.join(params.save_dir_results, dataset_path_all_4['key']), exist_ok=True)\n",
        "\n",
        "    params.train_dataset = os.path.join('/content/', dataset_path_all_4['key'])\n",
        "    params.test_fake_path = os.path.join('/content/', dataset_path_all_4['fake_path'])\n",
        "    params.test_masks_ground_truth_path = os.path.join('/content/', dataset_path_all_4['masks_path'])\n",
        "    params.test_real_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path_all_4['real_path'])\n",
        "\n",
        "    params.task_type = 'fully_supervised_localization_with_real_images'\n",
        "    # if 'sam' in first_step_type and (dataset_path['key'] == 'lama' or dataset_path['key'] == 'pluralistic'):\n",
        "    #         prev_arch = params.arch\n",
        "    #         params.arch = 'SAM2'\n",
        "    data_loader = get_dataloader(params)\n",
        "    # if 'sam' in first_step_type and (dataset_path['key'] == 'lama' or dataset_path['key'] == 'pluralistic'):\n",
        "    #     params.arch = prev_arch\n",
        "    params.task_type = 'fully_supervised_localization'\n",
        "\n",
        "    if params.task_type == 'fully_supervised_localization':\n",
        "        ious, f1_best, f1_fixed, ap, original_img_paths = validate_ensemble_fully_supervised_localization(\n",
        "            two_step_model, data_loader, dataset_path_all_4['key'], params.save_dir_results\n",
        "        )\n",
        "        save_image_localization_scores_to_file(ious, f1_best, f1_fixed, ap, original_img_paths, params, dataset_path_all_4['key'])\n",
        "\n",
        "        mean_iou = compute_mean_iou(ious, verbose=True, extra_text=dataset_path_all_4['key'])\n",
        "        mean_f1_best, mean_f1_fixed = compute_mean_f1(f1_best, f1_fixed, verbose=True, extra_text=dataset_path_all_4['key'])\n",
        "        mean_ap = compute_mean_ap(ap, verbose=True, extra_text=dataset_path_all_4['key'])\n",
        "\n",
        "        with open(os.path.join(params.save_dir_results, f\"scores_{dataset_path_all_4['key']}.txt\"), 'a') as f:\n",
        "            f.write(f\"{dataset_path_all_4['key']} \\t {mean_iou:.4f} \\t {mean_f1_best:.4f} \\t {mean_f1_fixed:.4f} \\t {mean_ap:.4f} \\n\")\n",
        "\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp7gp8zHfmcd",
        "outputId": "d2008acd-200f-4529-b17d-516df519e124"
      },
      "id": "qp7gp8zHfmcd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Two Step Model with first step type: detector on all datasets\n",
            "Testing on train_all_4_datasets\n",
            "Length of dataset:  4500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 141/141 [05:52<00:00,  2.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_all_4_datasetsMean IOU: 61.86\n",
            "train_all_4_datasetsMean F1 best: 0.7637\n",
            "train_all_4_datasetsMean F1 fixed: 0.7109\n",
            "train_all_4_datasetsMean AP: 0.5855\n",
            "\n",
            "Testing Two Step Model with first step type: classifier_sam on all datasets\n",
            "Testing on train_all_4_datasets\n",
            "Length of dataset:  4500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 141/141 [06:25<00:00,  2.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_all_4_datasetsMean IOU: 69.09\n",
            "train_all_4_datasetsMean F1 best: 0.7886\n",
            "train_all_4_datasetsMean F1 fixed: 0.7524\n",
            "train_all_4_datasetsMean AP: 0.5868\n",
            "\n",
            "Testing Two Step Model with first step type: classifier_clip on all datasets\n",
            "Testing on train_all_4_datasets\n",
            "Length of dataset:  4500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 141/141 [05:47<00:00,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_all_4_datasetsMean IOU: 66.61\n",
            "train_all_4_datasetsMean F1 best: 0.7907\n",
            "train_all_4_datasetsMean F1 fixed: 0.7538\n",
            "train_all_4_datasetsMean AP: 0.5824\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# second test will only use deepfake images, therefore we are only interested in using the classifier two-step model (to compare the 4 specialists with 1 generalist - which doesn't need a classifier to specify the type of the deepfake)\n",
        "# indeed, we could have used a classifier that only saw fake images (and learned to distinguish between them, but that would be quite specific, we would rather want to classify real images as well)\n",
        "\n",
        "# here we will use the 4 datasets directly\n",
        "\n",
        "for first_step_type in two_step_models.keys():\n",
        "    if first_step_type == 'detector':\n",
        "        continue\n",
        "    params.save_dir_results = f'{save_dir_res}_2_step_model_{first_step_type}_on_specific_datasets'\n",
        "    two_step_model = two_step_models[first_step_type]\n",
        "    print(f'Testing Two Step Model with first step type: {first_step_type} on specific datasets')\n",
        "\n",
        "    for dataset_path in dataset_paths:\n",
        "        if 'autosplice' in dataset_path['key']:\n",
        "            continue\n",
        "        print(f\"Testing on {dataset_path['key']}\")\n",
        "        set_seed()\n",
        "        os.makedirs(os.path.join(params.save_dir_results, dataset_path['key']), exist_ok=True)\n",
        "\n",
        "        params.train_dataset = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['key'])\n",
        "        params.test_fake_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['fake_path'])\n",
        "        params.test_masks_ground_truth_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['masks_path'])\n",
        "        params.test_real_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['real_path'])\n",
        "\n",
        "        # if 'sam' in first_step_type and (dataset_path['key'] == 'lama' or dataset_path['key'] == 'pluralistic'):\n",
        "            # prev_arch = params.arch\n",
        "            # params.arch = 'SAM2'\n",
        "        data_loader = get_dataloader(params)\n",
        "        # if 'sam' in first_step_type and (dataset_path['key'] == 'lama' or dataset_path['key'] == 'pluralistic'):\n",
        "            # params.arch = prev_arch\n",
        "\n",
        "        # create the directory for dataset results\n",
        "        os.makedirs(os.path.join(params.save_dir_results, params.train_dataset), exist_ok=True)\n",
        "\n",
        "        if params.task_type == 'fully_supervised_localization':\n",
        "            ious, f1_best, f1_fixed, ap, original_img_paths = validate_ensemble_fully_supervised_localization(\n",
        "                two_step_models[first_step_type], data_loader, dataset_path['key'], params.save_dir_results\n",
        "            )\n",
        "            save_image_localization_scores_to_file(ious, f1_best, f1_fixed, ap, original_img_paths, params, dataset_path['key'])\n",
        "\n",
        "            mean_iou = compute_mean_iou(ious, verbose=True, extra_text=dataset_path['key'])\n",
        "            mean_f1_best, mean_f1_fixed = compute_mean_f1(f1_best, f1_fixed, verbose=True, extra_text=dataset_path['key'])\n",
        "            mean_ap = compute_mean_ap(ap, verbose=True, extra_text=dataset_path['key'])\n",
        "\n",
        "            with open(os.path.join(params.save_dir_results, f\"scores_{dataset_path['key']}.txt\"), 'a') as f:\n",
        "                f.write(f\"{dataset_path['key']} \\t {mean_iou:.4f} \\t {mean_f1_best:.4f} \\t {mean_f1_fixed:.4f} \\t {mean_ap:.4f} \\n\")\n",
        "\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wbcSj7YziB-",
        "outputId": "05c1ec55-781c-43cd-931f-e7fc5f0e3393"
      },
      "id": "-wbcSj7YziB-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Two Step Model with first step type: classifier_sam on specific datasets\n",
            "Testing on lama\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [01:39<00:00,  3.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lamaMean IOU: 91.49\n",
            "lamaMean F1 best: 0.9646\n",
            "lamaMean F1 fixed: 0.953\n",
            "lamaMean AP: 0.9808\n",
            "\n",
            "Testing on ldm\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [01:23<00:00,  2.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ldmMean IOU: 49.66\n",
            "ldmMean F1 best: 0.7032\n",
            "ldmMean F1 fixed: 0.577\n",
            "ldmMean AP: 0.6966\n",
            "\n",
            "Testing on pluralistic\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [01:35<00:00,  3.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pluralisticMean IOU: 75.37\n",
            "pluralisticMean F1 best: 0.8378\n",
            "pluralisticMean F1 fixed: 0.8255\n",
            "pluralisticMean AP: 0.8156\n",
            "\n",
            "Testing on repaint-p2-9k\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [01:11<00:00,  2.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repaint-p2-9kMean IOU: 33.36\n",
            "repaint-p2-9kMean F1 best: 0.482\n",
            "repaint-p2-9kMean F1 fixed: 0.4512\n",
            "repaint-p2-9kMean AP: 0.4409\n",
            "\n",
            "Testing Two Step Model with first step type: classifier_clip on specific datasets\n",
            "Testing on lama\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [01:21<00:00,  2.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lamaMean IOU: 84.47\n",
            "lamaMean F1 best: 0.9712\n",
            "lamaMean F1 fixed: 0.9565\n",
            "lamaMean AP: 0.9643\n",
            "\n",
            "Testing on ldm\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [01:23<00:00,  2.86s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ldmMean IOU: 49.84\n",
            "ldmMean F1 best: 0.7046\n",
            "ldmMean F1 fixed: 0.5793\n",
            "ldmMean AP: 0.6981\n",
            "\n",
            "Testing on pluralistic\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [01:18<00:00,  2.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pluralisticMean IOU: 69.74\n",
            "pluralisticMean F1 best: 0.8406\n",
            "pluralisticMean F1 fixed: 0.8224\n",
            "pluralisticMean AP: 0.801\n",
            "\n",
            "Testing on repaint-p2-9k\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29/29 [01:10<00:00,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repaint-p2-9kMean IOU: 34.0\n",
            "repaint-p2-9kMean F1 best: 0.4872\n",
            "repaint-p2-9kMean F1 fixed: 0.4607\n",
            "repaint-p2-9kMean AP: 0.4486\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "for folder in os.listdir(f'/content/experiments/{params.experiment_name}'):\n",
        "    shutil.make_archive(f'{folder}', 'zip', f'/content/experiments/{params.experiment_name}/{folder}')\n",
        "    files.download(f'results_{folder}.zip')"
      ],
      "metadata": {
        "id": "9eTHb7HlMFMy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5b4b01ba-81d7-4062-8154-343de206c076"
      },
      "id": "9eTHb7HlMFMy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2d2dd9e1-ac75-42dc-953f-666248c3ef48\", \"results_results.zip\", 154)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_febbec43-7b76-46ee-b268-5d14a3f6c6cc\", \"results_results_2_step_model_classifier_sam_on_specific_datasets.zip\", 19075528)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d02144d8-b4c3-4b2c-b4ac-496f9912891b\", \"results_results_2_step_model_detector_on_specific_datasets+real_images.zip\", 21342595)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_029f42f6-8161-4a7f-b174-71b93d80a552\", \"results_results_2_step_model_classifier_clip_on_specific_datasets.zip\", 14773765)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_909dceae-3752-49a8-ba5e-ad0306551232\", \"results_results_2_step_model_classifier_clip_on_specific_datasets+real_images.zip\", 15963254)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9d92d566-b782-4892-82d4-8e84dff1311a\", \"results_results_2_step_model_classifier_sam_on_all_datasets.zip\", 19568793)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0b1193be-7183-41d2-ac94-16cb59af5e8c\", \"results_results_2_step_model_classifier_sam_on_specific_datasets+real_images.zip\", 20480105)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_55ea20cd-b30b-417b-9190-32050d200f0f\", \"results_models.zip\", 22)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6ec553f0-eb38-4e16-8761-2e7c01b9550c\", \"results_results_2_step_model_detector_on_all_datasets.zip\", 19443497)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0298383c-e3ac-4a42-a183-d23003261dbf\", \"results_results_2_step_model_classifier_clip_on_all_datasets.zip\", 15245586)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qt20PI9WFsmb"
      },
      "id": "qt20PI9WFsmb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}