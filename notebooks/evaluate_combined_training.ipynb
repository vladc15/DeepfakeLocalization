{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90198a98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90198a98",
        "outputId": "45a46b65-b885-4659-ba9d-2eb826fbc384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# update working directory\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom')"
      ],
      "metadata": {
        "id": "mXmVMLyLr5ar"
      },
      "id": "mXmVMLyLr5ar",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub5HUP6or_7w",
        "outputId": "759676c7-c9a4-4f2c-9f5c-124ac90480f7"
      },
      "id": "ub5HUP6or_7w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m127.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from parameters import Parameters\n",
        "from deepfake_datasets import LOCALIZATION_DATASET_PATHS, DETECTION_DATASET_PATHS\n",
        "from deepfake_datasets.datasets import get_dataloader\n",
        "from models.declip import get_model\n",
        "from models.declip_detection import get_detection_model\n",
        "from train.validate import validate_detection, validate_fully_supervised_localization, validate_fully_supervised_localization_real_images\n",
        "from utils.utils import compute_mean_iou, compute_mean_f1, compute_mean_ap, compute_mean_acc_detection, compute_mean_ap_detection"
      ],
      "metadata": {
        "id": "QpmTb67Ur4kG"
      },
      "id": "QpmTb67Ur4kG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb5e0f6",
      "metadata": {
        "id": "fdb5e0f6"
      },
      "outputs": [],
      "source": [
        "# set seed for reproducibility\n",
        "SEED = 0\n",
        "def set_seed():\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "# save image predictions to files\n",
        "def save_image_localization_scores_to_file(ious, f1_best, f1_fixed, aps, img_paths, params, dataset_name):\n",
        "    with open(params.save_dir_results + f\"/scores_{dataset_name}.txt\", 'a') as f:\n",
        "        f.write(f'image path \\t iou \\t f1_best \\t f1_fixed \\t ap\\n')\n",
        "        for iou, f1_b, f1_f, ap, img_path in zip(ious, f1_best, f1_fixed, aps, img_paths):\n",
        "            f.write(f'{img_path} \\t {iou} \\t {f1_b} \\t {f1_f} \\t {ap}\\n')\n",
        "\n",
        "# constants for image processing\n",
        "MEAN = {\n",
        "    \"imagenet\":[0.485, 0.456, 0.406],\n",
        "    \"clip\":[0.48145466, 0.4578275, 0.40821073]\n",
        "}\n",
        "STD = {\n",
        "    \"imagenet\":[0.229, 0.224, 0.225],\n",
        "    \"clip\":[0.26862954, 0.26130258, 0.27577711]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b46c6d",
      "metadata": {
        "id": "d6b46c6d"
      },
      "outputs": [],
      "source": [
        "# set parameters\n",
        "params = Parameters()\n",
        "\n",
        "# set the experiment name and output directory\n",
        "# alert if the experiment name is not set or the output directory already exists\n",
        "params.experiment_name = 'test_initial_training'\n",
        "assert params.experiment_name != '', 'Please set the experiment name'\n",
        "experiment_path = f'/content/experiments/{params.experiment_name}'\n",
        "if os.path.exists(experiment_path):\n",
        "    shutil.rmtree(experiment_path)\n",
        "params.create_output_dirs()\n",
        "\n",
        "# set data labels to test\n",
        "params.data_label = 'test'\n",
        "\n",
        "# set the model checkpoint path\n",
        "params.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/combined_training/test_lama/best_localization_model_vit+rn50_conv12_iou_58.0887_test_lama.pth'\n",
        "assert params.checkpoint_path != '', 'Please set the checkpoint path'\n",
        "\n",
        "# set model parameters for testing\n",
        "state_dict = torch.load(params.checkpoint_path, map_location='cpu')\n",
        "params.decoder_type = state_dict['decoder_type']\n",
        "params.feature_layer = state_dict['feature_layer']\n",
        "\n",
        "params.arch = 'CLIP:ViT-L/14,RN50'\n",
        "# params.arch = 'CLIP:RN50'\n",
        "\n",
        "params.task_type = 'fully_supervised_localization'\n",
        "\n",
        "# params.test_real_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/datasets/dolos_data/celebahq/'\n",
        "\n",
        "# set the batch size and num threads\n",
        "params.batch_size = 64\n",
        "params.num_threads = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e352a588",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e352a588",
        "outputId": "840e5f45-e747-4998-9562-2daf5893570e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 890M/890M [00:02<00:00, 362MiB/s]\n",
            "100%|████████████████████████████████████████| 244M/244M [00:02<00:00, 110MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# load the model\n",
        "model = get_model(params)\n",
        "model.load_state_dict(state_dict['model'], strict=False)\n",
        "model = model.cuda()\n",
        "model.eval()\n",
        "\n",
        "print('Model loaded successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad970795",
      "metadata": {
        "id": "ad970795"
      },
      "outputs": [],
      "source": [
        "# prepare the datasets and the results file\n",
        "if params.task_type == 'fully_supervised_localization' or params.task_type == 'fully_supervised_localization_real_images':\n",
        "    dataset_paths = LOCALIZATION_DATASET_PATHS\n",
        "    with open(os.path.join(params.save_dir_results, 'scores.txt'), 'a') as f:\n",
        "        f.write('dataset \\t iou \\t f1_best \\t f1_fixed \\t ap \\n')\n",
        "elif params.task_type == 'detection':\n",
        "    dataset_paths = DETECTION_DATASET_PATHS\n",
        "    with open(os.path.join(params.save_dir_results, 'scores.txt'), 'a') as f:\n",
        "        f.write('dataset \\t ap \\t acc_fixed_thresh \\t acc_best_thresh \\t best_threshold \\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8325f050",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8325f050",
        "outputId": "373bbd53-424b-43fd-c76e-2f0cb374baa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on lama\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [02:35<00:00, 10.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lamaMean IOU: 61.61\n",
            "lamaMean F1 best: 0.8394\n",
            "lamaMean F1 fixed: 0.7461\n",
            "lamaMean AP: 0.843\n",
            "\n",
            "Testing on ldm\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [02:45<00:00, 11.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ldmMean IOU: 45.75\n",
            "ldmMean F1 best: 0.6639\n",
            "ldmMean F1 fixed: 0.539\n",
            "ldmMean AP: 0.6664\n",
            "\n",
            "Testing on pluralistic\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [02:16<00:00,  9.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pluralisticMean IOU: 72.7\n",
            "pluralisticMean F1 best: 0.9067\n",
            "pluralisticMean F1 fixed: 0.842\n",
            "pluralisticMean AP: 0.9031\n",
            "\n",
            "Testing on repaint-p2-9k\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [03:35<00:00, 14.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repaint-p2-9kMean IOU: 62.32\n",
            "repaint-p2-9kMean F1 best: 0.8076\n",
            "repaint-p2-9kMean F1 fixed: 0.7294\n",
            "repaint-p2-9kMean AP: 0.8121\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# start the testing process\n",
        "for dataset_path in dataset_paths:\n",
        "    if 'autosplice' in dataset_path['key']:\n",
        "        continue\n",
        "    print(f\"Testing on {dataset_path['key']}\")\n",
        "    set_seed()\n",
        "    os.makedirs(os.path.join(params.save_dir_results, dataset_path['key']), exist_ok=True)\n",
        "\n",
        "    params.train_dataset = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['key'])\n",
        "    params.test_fake_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['fake_path'])\n",
        "    params.test_masks_ground_truth_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['masks_path'])\n",
        "    if params.task_type == 'detection' or  params.task_type == 'fully_supervised_localization_real_images' or params.task_type == 'classification':\n",
        "        params.test_real_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['real_path'])\n",
        "\n",
        "    data_loader = get_dataloader(params)\n",
        "\n",
        "    # create the directory for dataset results\n",
        "    os.makedirs(os.path.join(params.save_dir_results, params.train_dataset), exist_ok=True)\n",
        "\n",
        "    if params.task_type == 'fully_supervised_localization_real_images':\n",
        "        validate_fully_supervised_localization_real_images(\n",
        "            model, data_loader, dataset_path['key'], params.save_dir_results\n",
        "        )\n",
        "\n",
        "    elif params.task_type == 'fully_supervised_localization':\n",
        "        ious, f1_best, f1_fixed, ap, original_img_paths = validate_fully_supervised_localization(\n",
        "            model, data_loader, dataset_path['key'], params.save_dir_results\n",
        "        )\n",
        "        save_image_localization_scores_to_file(ious, f1_best, f1_fixed, ap, original_img_paths, params, dataset_path['key'])\n",
        "\n",
        "        mean_iou = compute_mean_iou(ious, verbose=True, extra_text=dataset_path['key'])\n",
        "        mean_f1_best, mean_f1_fixed = compute_mean_f1(f1_best, f1_fixed, verbose=True, extra_text=dataset_path['key'])\n",
        "        mean_ap = compute_mean_ap(ap, verbose=True, extra_text=dataset_path['key'])\n",
        "\n",
        "        with open(os.path.join(params.save_dir_results, f\"scores_{dataset_path['key']}.txt\"), 'a') as f:\n",
        "            f.write(f\"{dataset_path['key']} \\t {mean_iou:.4f} \\t {mean_f1_best:.4f} \\t {mean_f1_fixed:.4f} \\t {mean_ap:.4f} \\n\")\n",
        "\n",
        "    elif params.task_type == 'detection' or params.task_type == 'classification':\n",
        "        mean_ap, mean_acc, _ = validate_detection(\n",
        "            model, data_loader\n",
        "        )\n",
        "\n",
        "        print(f'Dataset: {dataset_path[\"key\"]} - AP: {mean_ap:.4f} - Acc: {mean_acc:.4f}')\n",
        "        # with open(os.path.join(params.save_dir_results, f\"scores_{dataset_path['key']}.txt\"), 'a') as f:\n",
        "        #     f.write(f\"{dataset_path['key']} \\t {mean_ap:.4f} \\t {mean_acc_fixed_thresh:.4f} \\t {mean_acc_best_thresh:.4f} \\t {best_threshold:.4f} \\n\")\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Arhivare folder\n",
        "shutil.make_archive(f'results_{params.checkpoint_path}', 'zip', '/content/experiments/test_initial_training/results')\n",
        "\n",
        "# Descărcare\n",
        "files.download(f'results_{params.checkpoint_path}.zip')"
      ],
      "metadata": {
        "id": "M6nzplDEk8NZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88bc95b1-79ce-492a-8bac-543d1ef94a9c"
      },
      "id": "M6nzplDEk8NZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_04890387-241d-4392-add4-0604ad7c15cc\", \"best_localization_model_vit+rn50_conv12_iou_58.0887_test_lama.pth.zip\", 18452706)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}