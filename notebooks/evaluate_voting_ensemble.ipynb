{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90198a98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90198a98",
        "outputId": "eccc1ed9-f164-4b86-ca86-c94269743f5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mXmVMLyLr5ar",
      "metadata": {
        "id": "mXmVMLyLr5ar"
      },
      "outputs": [],
      "source": [
        "# update working directory\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ub5HUP6or_7w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub5HUP6or_7w",
        "outputId": "05911230-5c5a-453c-bd70-7610971ef734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QpmTb67Ur4kG",
      "metadata": {
        "id": "QpmTb67Ur4kG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "\n",
        "from parameters import Parameters\n",
        "from deepfake_datasets import LOCALIZATION_DATASET_PATHS, DETECTION_DATASET_PATHS\n",
        "from deepfake_datasets.datasets import get_dataloader\n",
        "from models.voting_ensemble import VotingEnsembleModel\n",
        "from train.validate import validate_detection, validate_fully_supervised_localization, validate_ensemble_fully_supervised_localization\n",
        "from utils.utils import compute_mean_iou, compute_mean_f1, compute_mean_ap, compute_mean_acc_detection, compute_mean_ap_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb5e0f6",
      "metadata": {
        "id": "fdb5e0f6"
      },
      "outputs": [],
      "source": [
        "# set seed for reproducibility\n",
        "SEED = 0\n",
        "def set_seed():\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "# save image predictions to files\n",
        "def save_image_localization_scores_to_file(ious, f1_best, f1_fixed, aps, img_paths, params):\n",
        "    with open(params.save_dir_results + \"/scores.txt\", 'w') as f:\n",
        "        f.write(f'image path \\t iou \\t f1_best \\t f1_fixed \\t ap\\n')\n",
        "        for iou, f1_b, f1_f, ap, img_path in zip(ious, f1_best, f1_fixed, aps, img_paths):\n",
        "            f.write(f'{img_path} \\t {iou} \\t {f1_b} \\t {f1_f} \\t {ap}\\n')\n",
        "\n",
        "# constants for image processing\n",
        "MEAN = {\n",
        "    \"imagenet\":[0.485, 0.456, 0.406],\n",
        "    \"clip\":[0.48145466, 0.4578275, 0.40821073]\n",
        "}\n",
        "STD = {\n",
        "    \"imagenet\":[0.229, 0.224, 0.225],\n",
        "    \"clip\":[0.26862954, 0.26130258, 0.27577711]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b46c6d",
      "metadata": {
        "id": "d6b46c6d"
      },
      "outputs": [],
      "source": [
        "# set parameters\n",
        "params = Parameters()\n",
        "\n",
        "# set the experiment name and output directory\n",
        "# alert if the experiment name is not set or the output directory already exists\n",
        "params.experiment_name = 'test_ensemble'\n",
        "assert params.experiment_name != '', 'Please set the experiment name'\n",
        "params.create_output_dirs()\n",
        "\n",
        "# set data labels to test\n",
        "params.data_label = 'test'\n",
        "\n",
        "# uncomment lines below to set new datasets\n",
        "new_root_path = '/content/datasets/dolos_data/celebahq/'\n",
        "new_dataset_name = 'ldm'\n",
        "params.update_dolos_data_paths(new_root_path, new_dataset_name)\n",
        "\n",
        "# set the model checkpoint path\n",
        "params.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/best_localization_model_iou_47.47_conv12_26_epochs.pth'\n",
        "assert params.checkpoint_path != '', 'Please set the checkpoint path'\n",
        "\n",
        "# set model parameters for testing\n",
        "# state_dict = torch.load(params.checkpoint_path, map_location='cpu')\n",
        "# params.decoder_type = state_dict['decoder_type']\n",
        "# params.feature_layer = state_dict['feature_layer']\n",
        "\n",
        "# set the batch size and num threads\n",
        "params.batch_size = 64\n",
        "params.num_threads = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e352a588",
      "metadata": {
        "id": "e352a588"
      },
      "outputs": [],
      "source": [
        "params_vit = copy.deepcopy(params)\n",
        "params_vit.arch = 'CLIP:ViT-L/14'\n",
        "params_vit.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/best_localization_model_vit_iou_47.47_conv12_26_epochs.pth'\n",
        "state_dict_vit = torch.load(params_vit.checkpoint_path, map_location='cpu')\n",
        "params_vit.decoder_type = state_dict_vit['decoder_type']\n",
        "params_vit.feature_layer = state_dict_vit['feature_layer']\n",
        "\n",
        "params_rn50 = copy.deepcopy(params)\n",
        "params_rn50.arch = 'CLIP:RN50'\n",
        "params_rn50.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/best_localization_model_rn50_iou_45.57_conv12_45_epochs.pth'\n",
        "state_dict_rn50 = torch.load(params_rn50.checkpoint_path, map_location='cpu')\n",
        "params_rn50.decoder_type = state_dict_rn50['decoder_type']\n",
        "params_rn50.feature_layer = state_dict_rn50['feature_layer']\n",
        "\n",
        "params_vit_rn50 = copy.deepcopy(params)\n",
        "params_vit_rn50.arch = 'CLIP:ViT-L/14,RN50'\n",
        "params_vit_rn50.checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/trained_models/best_localization_model_vit+rn50_iou_46_conv4_19_epochs.pth'\n",
        "state_dict_vit_rn50 = torch.load(params_vit_rn50.checkpoint_path, map_location='cpu')\n",
        "params_vit_rn50.decoder_type = state_dict_vit_rn50['decoder_type']\n",
        "params_vit_rn50.feature_layer = state_dict_vit_rn50['feature_layer']\n",
        "\n",
        "models_params = [params_vit, params_rn50, params_vit_rn50]\n",
        "state_dicts = [state_dict_vit, state_dict_rn50, state_dict_vit_rn50]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hard_voting_ensemble = VotingEnsembleModel(models_params, state_dicts, voting_method='hard')\n",
        "soft_voting_ensemble = VotingEnsembleModel(models_params, state_dicts, voting_method='soft')"
      ],
      "metadata": {
        "id": "kFzJepfe7zwq"
      },
      "id": "kFzJepfe7zwq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad970795",
      "metadata": {
        "id": "ad970795"
      },
      "outputs": [],
      "source": [
        "# prepare the datasets and the results file\n",
        "if params.task_type == 'fully_supervised_localization':\n",
        "    dataset_paths = LOCALIZATION_DATASET_PATHS\n",
        "    with open(os.path.join(params.save_dir_results, 'scores.txt'), 'a') as f:\n",
        "        f.write('dataset \\t iou \\t f1_best \\t f1_fixed \\t ap \\n')\n",
        "elif params.task_type == 'detection':\n",
        "    dataset_paths = DETECTION_DATASET_PATHS\n",
        "    with open(os.path.join(params.save_dir_results, 'scores.txt'), 'a') as f:\n",
        "        f.write('dataset \\t ap \\t acc_fixed_thresh \\t acc_best_thresh \\t best_threshold \\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8325f050",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8325f050",
        "outputId": "cb6c46d0-1049-47e3-8e27-8f410690bcc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing on lama\n",
            "Testing hard voting ensemble\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 2/15 [00:20<02:06,  9.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 6/15 [00:48<01:06,  7.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 7/15 [00:55<00:58,  7.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 8/15 [01:02<00:50,  7.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 10/15 [01:16<00:35,  7.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 11/15 [01:23<00:28,  7.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [01:31<00:21,  7.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [01:45<00:00,  7.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lamaMean IOU: 40.92\n",
            "lamaMean F1 best: 0.4968\n",
            "lamaMean F1 fixed: 0.4968\n",
            "lamaMean AP: 0.4719\n",
            "Testing soft voting ensemble\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [01:51<00:00,  7.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lamaMean IOU: 39.65\n",
            "lamaMean F1 best: 0.707\n",
            "lamaMean F1 fixed: 0.5003\n",
            "lamaMean AP: 0.679\n",
            "\n",
            "Testing on ldm\n",
            "Testing hard voting ensemble\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 1/15 [00:12<02:59, 12.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 3/15 [00:27<01:40,  8.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 4/15 [00:34<01:26,  7.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 5/15 [00:41<01:15,  7.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 6/15 [00:48<01:06,  7.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 7/15 [00:55<00:58,  7.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 8/15 [01:02<00:50,  7.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 9/15 [01:09<00:43,  7.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 10/15 [01:16<00:35,  7.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 11/15 [01:23<00:28,  7.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [01:30<00:21,  7.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 13/15 [01:38<00:14,  7.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [01:45<00:00,  7.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ldmMean IOU: 49.12\n",
            "ldmMean F1 best: 0.5915\n",
            "ldmMean F1 fixed: 0.5915\n",
            "ldmMean AP: 0.5187\n",
            "Testing soft voting ensemble\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [01:51<00:00,  7.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ldmMean IOU: 48.35\n",
            "ldmMean F1 best: 0.7389\n",
            "ldmMean F1 fixed: 0.5991\n",
            "ldmMean AP: 0.7151\n",
            "\n",
            "Testing on pluralistic\n",
            "Testing hard voting ensemble\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 3/15 [00:27<01:41,  8.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 5/15 [00:41<01:16,  7.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 11/15 [01:24<00:28,  7.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [01:31<00:21,  7.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [01:45<00:00,  7.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pluralisticMean IOU: 52.96\n",
            "pluralisticMean F1 best: 0.6086\n",
            "pluralisticMean F1 fixed: 0.6086\n",
            "pluralisticMean AP: 0.5548\n",
            "Testing soft voting ensemble\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [01:51<00:00,  7.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pluralisticMean IOU: 52.59\n",
            "pluralisticMean F1 best: 0.7626\n",
            "pluralisticMean F1 fixed: 0.6122\n",
            "pluralisticMean AP: 0.7474\n",
            "\n",
            "Testing on repaint-p2-9k\n",
            "Testing hard voting ensemble\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 1/15 [00:13<03:08, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 2/15 [00:20<02:07,  9.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 3/15 [00:27<01:42,  8.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 7/15 [00:56<00:58,  7.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 9/15 [01:10<00:43,  7.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 10/15 [01:17<00:35,  7.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 11/15 [01:24<00:28,  7.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [01:31<00:21,  7.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n",
            "Empty predictions or ground truth, returning empty tensors in localization_f1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [01:46<00:00,  7.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repaint-p2-9kMean IOU: 43.77\n",
            "repaint-p2-9kMean F1 best: 0.5281\n",
            "repaint-p2-9kMean F1 fixed: 0.5281\n",
            "repaint-p2-9kMean AP: 0.4824\n",
            "Testing soft voting ensemble\n",
            "Length of dataset:  900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [01:52<00:00,  7.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repaint-p2-9kMean IOU: 43.11\n",
            "repaint-p2-9kMean F1 best: 0.6904\n",
            "repaint-p2-9kMean F1 fixed: 0.5305\n",
            "repaint-p2-9kMean AP: 0.6762\n",
            "\n",
            "Testing on autosplice_jpeg75\n",
            "Testing hard voting ensemble\n",
            "Length of dataset:  3621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/57 [00:38<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d20377d1834a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fully_supervised_localization'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing hard voting ensemble'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         ious, f1_best, f1_fixed, ap, original_img_paths = validate_ensemble_fully_supervised_localization(\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mhard_voting_ensemble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dir_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         )\n",
            "\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-custom/train/validate.py\u001b[0m in \u001b[0;36mvalidate_ensemble_fully_supervised_localization\u001b[0;34m(ensemble, data_loader, dataset_name, output_save_path)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of dataset: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks_paths\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;31m# mask processing for the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"ldm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lama\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pluralistic\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"repaint-p2-9k\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# start the testing process\n",
        "for dataset_path in dataset_paths:\n",
        "    print(f\"Testing on {dataset_path['key']}\")\n",
        "    set_seed()\n",
        "    os.makedirs(os.path.join(params.save_dir_results, dataset_path['key']), exist_ok=True)\n",
        "\n",
        "    params.train_dataset = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['key'])\n",
        "    params.test_fake_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['fake_path'])\n",
        "    params.test_masks_ground_truth_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['masks_path'])\n",
        "    if params.task_type == 'detection':\n",
        "        params.test_real_path = os.path.join('/content/drive/MyDrive/Colab Notebooks/Licenta/DeCLIP-main/', dataset_path['real_path'])\n",
        "\n",
        "    data_loader = get_dataloader(params)\n",
        "\n",
        "    # create the directory for dataset results\n",
        "    os.makedirs(os.path.join(params.save_dir_results, params.train_dataset), exist_ok=True)\n",
        "\n",
        "    if params.task_type == 'fully_supervised_localization':\n",
        "        print('Testing hard voting ensemble')\n",
        "        ious, f1_best, f1_fixed, ap, original_img_paths = validate_ensemble_fully_supervised_localization(\n",
        "            hard_voting_ensemble, data_loader, dataset_path['key'], params.save_dir_results\n",
        "        )\n",
        "        save_image_localization_scores_to_file(ious, f1_best, f1_fixed, ap, original_img_paths, params)\n",
        "\n",
        "        mean_iou = compute_mean_iou(ious, verbose=True, extra_text=dataset_path['key'])\n",
        "        mean_f1_best, mean_f1_fixed = compute_mean_f1(f1_best, f1_fixed, verbose=True, extra_text=dataset_path['key'])\n",
        "        mean_ap = compute_mean_ap(ap, verbose=True, extra_text=dataset_path['key'])\n",
        "\n",
        "        with open(os.path.join(params.save_dir_results, 'scores.txt'), 'a') as f:\n",
        "            f.write(f\"{dataset_path['key']} \\t {mean_iou:.4f} \\t {mean_f1_best:.4f} \\t {mean_f1_fixed:.4f} \\t {mean_ap:.4f} \\n\")\n",
        "\n",
        "\n",
        "        print('Testing soft voting ensemble')\n",
        "        ious, f1_best, f1_fixed, ap, original_img_paths = validate_ensemble_fully_supervised_localization(\n",
        "            soft_voting_ensemble, data_loader, dataset_path['key'], params.save_dir_results\n",
        "        )\n",
        "        save_image_localization_scores_to_file(ious, f1_best, f1_fixed, ap, original_img_paths, params)\n",
        "\n",
        "        mean_iou = compute_mean_iou(ious, verbose=True, extra_text=dataset_path['key'])\n",
        "        mean_f1_best, mean_f1_fixed = compute_mean_f1(f1_best, f1_fixed, verbose=True, extra_text=dataset_path['key'])\n",
        "        mean_ap = compute_mean_ap(ap, verbose=True, extra_text=dataset_path['key'])\n",
        "\n",
        "        with open(os.path.join(params.save_dir_results, 'scores.txt'), 'a') as f:\n",
        "            f.write(f\"{dataset_path['key']} \\t {mean_iou:.4f} \\t {mean_f1_best:.4f} \\t {mean_f1_fixed:.4f} \\t {mean_ap:.4f} \\n\")\n",
        "\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Arhivare folder\n",
        "shutil.make_archive('results_voting_ensemble_own', 'zip', '/content/experiments/test_ensemble/results')\n",
        "\n",
        "# Descărcare\n",
        "files.download('results_voting_ensemble_own.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9eTHb7HlMFMy",
        "outputId": "9b7a7635-067d-456b-e96c-0615bf1e5307"
      },
      "id": "9eTHb7HlMFMy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_86ddd77f-1b80-43ea-b5e0-eaa9c067f250\", \"results_voting_ensemble_own.zip\", 31583453)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}